{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Analyze GitHub Archive Data'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghdata = spark.read.table(f'{username}_raw.ghactivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghdata.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|type                         |\n",
      "+-----------------------------+\n",
      "|PullRequestReviewEvent       |\n",
      "|PushEvent                    |\n",
      "|GollumEvent                  |\n",
      "|ReleaseEvent                 |\n",
      "|CommitCommentEvent           |\n",
      "|CreateEvent                  |\n",
      "|PullRequestReviewCommentEvent|\n",
      "|IssueCommentEvent            |\n",
      "|DeleteEvent                  |\n",
      "|IssuesEvent                  |\n",
      "|ForkEvent                    |\n",
      "|PublicEvent                  |\n",
      "|MemberEvent                  |\n",
      "|WatchEvent                   |\n",
      "|PullRequestEvent             |\n",
      "+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ghdata. \\\n",
    "    select('type'). \\\n",
    "    distinct(). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  ref_type|\n",
      "+----------+\n",
      "|      null|\n",
      "|       tag|\n",
      "|    branch|\n",
      "|repository|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ghdata. \\\n",
    "    select('payload.ref_type'). \\\n",
    "    distinct(). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|  ref_type|event_count|\n",
      "+----------+-----------+\n",
      "|      null|    8550769|\n",
      "|    branch|    1183829|\n",
      "|repository|     438739|\n",
      "|       tag|     131003|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, col, lit\n",
    "\n",
    "ghdata. \\\n",
    "    groupBy('payload.ref_type'). \\\n",
    "    agg(count(lit(1)).alias('event_count')). \\\n",
    "    orderBy(col('event_count').desc()). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5686929"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ghdata.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import substring, count, col, lit\n",
    "\n",
    "ghdata. \\\n",
    "    filter('payload.ref_type = \"repository\" AND type = \"CreateEvent\"'). \\\n",
    "    groupBy(substring('created_at', 1, 10).alias('created_dt')). \\\n",
    "    agg(count(lit(1)).alias('repo_count')). \\\n",
    "    orderBy('created_dt'). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
